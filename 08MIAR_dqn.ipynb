{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSVPAihG4U1j"
      },
      "source": [
        "# Actividad - Proyecto práctico\n",
        "\n",
        "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
        "* Alumno 1: Benali, Abdelilah\n",
        "* Alumno 2: Cuesta Cifuentes, Jair\n",
        "* Alumno 3: González Huete, Manel\n",
        "* Alumno 4: Manzanas Mogrovejo, Francisco\n",
        "* Alumno 5: Pascual, Guadalupe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWWcufoC7S2B"
      },
      "source": [
        "---\n",
        "## **PARTE 1** - Instalación y requisitos previos\n",
        "\n",
        "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
        "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
        "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
        "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
        "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1svUw2WiJAUy"
      },
      "source": [
        "---\n",
        "### 1.1. Preparar enviroment (solo local)\n",
        "\n",
        "\n",
        "\n",
        "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
        "1. En Windows, puede ser necesario instalar las C++ Build Tools. Para ello, siga los siguientes pasos: https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30.\n",
        "2. Instalar Anaconda\n",
        "3. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
        "\n",
        "\n",
        "```\n",
        "conda update --all\n",
        "conda create --name miar_rl python=3.8\n",
        "conda activate miar_rl\n",
        "cd \"PATH_TO_FOLDER\"\n",
        "conda install git\n",
        "pip install jupyter\n",
        "```\n",
        "\n",
        "\n",
        "4. Abrir la notebook con *jupyter-notebook*.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "jupyter-notebook\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouO30DIAKL3"
      },
      "source": [
        "---\n",
        "### 1.2. Localizar entorno de trabajo: Google colab o local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cw5W3OopAFKN"
      },
      "outputs": [],
      "source": [
        "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
        "mount='/content/gdrive'\n",
        "drive_root = mount + \"/My Drive/VIU/08_AR_MIAR/sesiones_practicas/sesion_practica_1\"\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False\n",
        "\n",
        "IN_COLAB=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK5sY_ybAFt8"
      },
      "source": [
        "---\n",
        "### 1.3. Montar carpeta de datos local (solo Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lN7KLe05NSa",
        "outputId": "d1c8fb12-a6ef-48fe-e2c1-8217516e930f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos en el directorio: \n",
            "['.config', 'checkpoint', 'dqn_SpaceInvaders-v0_weights.h5f.data-00000-of-00001', 'dqn_BreakoutDeterministic-v4_log.json', 'checkpoints', 'dqn_BreakoutDeterministic-v4_weights.h5f.index', 'dqn_SpaceInvaders-v0_log.json', 'DQN_log.json', 'dqn_SpaceInvaders-v0_weights.h5f.index', 'dqn_BreakoutDeterministic-v4_weights.h5f.data-00000-of-00001', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# Switch to the directory on the Google Drive that you want to use\n",
        "import os\n",
        "if IN_COLAB:\n",
        "  print(\"We're running Colab\")\n",
        "\n",
        "  if IN_COLAB:\n",
        "    # Mount the Google Drive at mount\n",
        "    print(\"Colab: mounting Google drive on \", mount)\n",
        "\n",
        "    drive.mount(mount)\n",
        "\n",
        "    # Create drive_root if it doesn't exist\n",
        "    create_drive_root = True\n",
        "    if create_drive_root:\n",
        "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
        "      os.makedirs(drive_root, exist_ok=True)\n",
        "\n",
        "    # Change to the directory\n",
        "    print(\"\\nColab: Changing directory to \", drive_root)\n",
        "    %cd $drive_root\n",
        "# Verify we're in the correct working directory\n",
        "%pwd\n",
        "print(\"Archivos en el directorio: \")\n",
        "print(os.listdir())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2zVSAPW43MH"
      },
      "source": [
        "---\n",
        "### 1.4. Instalar librerías necesarias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AmVd8L9XBt26"
      },
      "outputs": [],
      "source": [
        "IN_LOCAL = True\n",
        "\n",
        "if IN_COLAB:\n",
        "  %pip install gym==0.17.3\n",
        "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
        "  %pip install keras-rl2==1.0.5\n",
        "  %pip install tensorflow==2.8\n",
        "if not IN_LOCAL:\n",
        "  %pip install numpy==1.23.5\n",
        "  %pip install gym==0.17\n",
        "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
        "  %pip install pyglet==1.5.0\n",
        "  %pip install h5py==3.1.0\n",
        "  %pip install Pillow==9.5.0\n",
        "  %pip install keras-rl2==1.0.5\n",
        "  %pip install Keras==2.2.4\n",
        "  %pip install tensorflow==2.5.3\n",
        "  %pip install torch==2.0.1\n",
        "  %pip install agents==1.4.0\n",
        "  %pip install matplotlib==3.4.3\n",
        "  %pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihTI9TOD43ML"
      },
      "source": [
        "---\n",
        "## **PARTE 2**. Enunciado\n",
        "\n",
        "Consideraciones a tener en cuenta:\n",
        "\n",
        "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
        "\n",
        "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
        "\n",
        "Este proyecto práctico consta de tres partes:\n",
        "\n",
        "1.   Implementar la red neuronal que se usará en la solución\n",
        "2.   Implementar las distintas piezas de la solución DQN\n",
        "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
        "\n",
        "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
        "\n",
        "IMPORTANTE:\n",
        "\n",
        "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
        "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
        "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
        "* Cada alumno deberá de subir la solución de forma individual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIAR9zQv43MO"
      },
      "source": [
        "---\n",
        "## **PARTE 3**. Desarrollo y preguntas\n",
        "\n",
        "#### Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K4o4-N4T43MO"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import gc       # Para garbage collection\n",
        "import random\n",
        "import os\n",
        "import pickle\n",
        "import re       # Para expresiones regulares en carga de checkpoints\n",
        "import gym      # Para el entorno de Atari\n",
        "import cv2      # Para preprocesamiento de imágenes si se usa AtariProcessor\n",
        "import warnings\n",
        "import time\n",
        "import psutil\n",
        "import tracemalloc\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.agents.dqn import DQNAgent, AbstractDQNAgent\n",
        "\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Activation, Flatten, Convolution2D, Permute\n",
        "from tensorflow.keras.layers import Lambda, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "from collections import deque\n",
        "from tqdm import trange     # Necesaria para la barra de progreso en simple_train\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necesario para la grabación de video\n",
        "try:\n",
        "    import gym.wrappers\n",
        "except ImportError:\n",
        "    print(\"WARNING: gym.wrappers no está disponible. La grabación de video no funcionará.\")\n",
        "    gym.wrappers = None # Asegurar que no dé error si no se encuentra\n"
      ],
      "metadata": {
        "id": "puzS2kTzc1Fd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar TensorFlow para CPU (x cores)\n",
        "def optimizar_tensorflow():\n",
        "    \"\"\"Configura TensorFlow para rendimiento óptimo en CPU/GPU\"\"\"\n",
        "    # Limpiar sesión previa\n",
        "    gc.collect()\n",
        "\n",
        "    # Optimización de GPU si está disponible\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            print(f\"GPU optimizada para crecimiento adaptativo de memoria\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error al configurar GPU: {e}\")\n",
        "\n",
        "    # Optimización de CPU\n",
        "    num_cpu_cores = os.cpu_count() or 8  # Fallback a 8 si no se puede detectar\n",
        "\n",
        "    os.environ[\"OMP_NUM_THREADS\"] = str(num_cpu_cores // 2)\n",
        "    os.environ[\"OPENBLAS_NUM_THREADS\"] = str(num_cpu_cores // 2)\n",
        "    os.environ[\"MKL_NUM_THREADS\"] = str(num_cpu_cores // 2)\n",
        "\n",
        "    tf.config.threading.set_intra_op_parallelism_threads(num_cpu_cores // 2)\n",
        "    tf.config.threading.set_inter_op_parallelism_threads(max(2, num_cpu_cores // 4))\n",
        "\n",
        "    # Modo eager solo si es necesario\n",
        "    # Para entrenamiento, es mejor desactivarlo por rendimiento\n",
        "    tf.config.run_functions_eagerly(False)\n",
        "\n",
        "    print(f\"TensorFlow optimizado para {num_cpu_cores} cores CPU\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "G8iRCStcc90p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Crear el entorno\n",
        "Nuestro entorno es el juego Space Invaders, de Atari"
      ],
      "metadata": {
        "id": "faNbnMuOdNDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el entorno\n",
        "env_name = 'SpaceInvaders-v0'\n",
        "env = gym.make(env_name)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n"
      ],
      "metadata": {
        "id": "7WFE0sqPdLsy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"El tamaño de nuestro 'frame' es: \", env.observation_space)\n",
        "print(\"El número de acciones posibles es : \", nb_actions)\n",
        "print(\"Las acciones posibles son : \",env.env.get_action_meanings())\n",
        "\n",
        "# Here we create an hot encoded version of our actions\n",
        "# possible_actions = [[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0]...]\n",
        "possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())\n",
        "print(\"\\nOHE de las acciones posibles: \\n\", possible_actions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcjoyH3idqh4",
        "outputId": "73f8d166-514b-4341-9256-0a06734a739b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El tamaño de nuestro 'frame' es:  Box(0, 255, (210, 160, 3), uint8)\n",
            "El número de acciones posibles es :  6\n",
            "Las acciones posibles son :  ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
            "\n",
            "OHE de las acciones posibles: \n",
            " [[1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición Hiperparámetros"
      ],
      "metadata": {
        "id": "tgw7iHVRduGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### HIPERPARÁMETROS DEL MODELO\n",
        "# Hiperparámetros optimizados\n",
        "HEIGHT = 84\n",
        "WIDTH = 84\n",
        "USE_FRAMESTACK = True       # Cambiar a True si quieres detección de movimiento\n",
        "WINDOW_LENGTH = 4 if USE_FRAMESTACK else 1   # Número de fotogramas apilados          # La mayoría de implementaciones usan 4 frames\n",
        "batch_size = 32             # Tamaño de batch óptimo\n",
        "gamma = 0.99                # Factor de descuento (mejor que 0.95 para recompensas a largo plazo)\n",
        "learning_rate = 0.00025     # Tasa de aprendizaje estándar para DQN\n",
        "memory_size = 1000000       # Buffer de memoria grande para mejor estabilidad\n",
        "TARGET_UPDATE_INTERVAL = 10000  # Actualización de red objetivo cada 10,000 pasos\n",
        "WARMUP_STEPS = 50000        # Pasos iniciales para llenar la memoria (experiencia aleatoria)\n",
        "TRAINING_STEPS = 5000000    # Total de pasos de entrenamiento (5M para buenos resultados)\n",
        "INPUT_SHAPE = (HEIGHT, WIDTH)                 # Dimensiones de cada frame\n",
        "\n",
        "### HIPERPARÁMETROS DE PREPROCESAMIENTO\n",
        "\n",
        "#CHANNELS_FIRST_SHAPE = (WINDOW_LENGTH, *INPUT_SHAPE)  # Para SequentialMemory (batch, channels, height, width)\n",
        "MODEL_INPUT_SHAPE = (HEIGHT, WIDTH, WINDOW_LENGTH)  # Forma para el modelo (channels_last)\n",
        "\n",
        "# Definir shape consistente\n",
        "if USE_FRAMESTACK:\n",
        "    state_shape = (84, 84, WINDOW_LENGTH)  # (84, 84, x)\n",
        "else:\n",
        "    state_shape = (84, 84, 1)  # (84, 84, 1) - escala de grises simple\n",
        "\n",
        "state_size = (*INPUT_SHAPE, WINDOW_LENGTH)   # Nuestra entrada es una pila de 4 fotogramas, por lo tanto 110x84x4 (ancho, alto, canales)\n",
        "input_shape = (*INPUT_SHAPE, WINDOW_LENGTH)  # Para la API de keras-rl\n",
        "action_size = env.action_space.n       # 6 acciones posibles\n",
        "learning_rate =  0.00025               # Alfa (también conocido como tasa de aprendizaje)\n",
        "\n",
        "### HIPERPARÁMETROS DE ENTRENAMIENTO\n",
        "# total_episodios = 10    #TEST        # Episodios totales para el entrenamiento\n",
        "# max_steps = 10000       #TEST        # Máximo de pasos posibles por episodio\n",
        "total_episodios = 100          # Episodios totales para el entrenamiento\n",
        "max_steps = 3000               # Máximo de pasos posibles por episodio\n",
        "\n",
        "# Parámetros de exploración para la estrategia epsilon-greedy\n",
        "epsilon_start = 1.0            # Probabilidad de exploración al inicio\n",
        "epsilon_stop = 0.01            # Probabilidad mínima de exploración\n",
        "decay_rate = 0.00001           # Tasa de decaimiento exponencial para la probabilidad de exploración\n",
        "epsilon_decay = 0.995\n",
        "\n",
        "# Hiperparámetros del aprendizaje Q\n",
        "tau = 0.001\n",
        "checkpoint_path=\"checkpoints\"\n",
        "\n",
        "### HIPERPARÁMETROS DE MEMORIA\n",
        "pretrain_length = batch_size   # Número de experiencias almacenadas en la memoria al inicializar por primera vez\n",
        "\n",
        "### CAMBIA ESTO A FALSE SI SOLO QUIERES VER AL AGENTE ENTRENADO\n",
        "training = False\n",
        "\n",
        "## CAMBIA ESTO A TRUE SI QUIERES RENDERIZAR EL ENTORNO\n",
        "episode_render = False"
      ],
      "metadata": {
        "id": "TshMrqTjdxja"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clase \"processor\" para Atari\n",
        "\n",
        "Ahora definimos un \"processor\" para las pantallas de entrada del juego, en el que recortamos el tamaño de la imagen (matriz de 210 x 160 píxeles) y la convertimos En una matriz bidimensional de 80 x 80 píxeles). También convertimos las imágenes de RGB a escala de grises normal, ya que no necesitamos usar los colores. Con este trabajo buscamos acelerar nuestro algoritmo, eliminando la información innecesaria y reduciendo la carga de la GPU."
      ],
      "metadata": {
        "id": "cjFRyr4Ld1Hp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "06wZVH5c43MP"
      },
      "outputs": [],
      "source": [
        "class AtariProcessor(Processor):\n",
        "    \"\"\"\n",
        "    Procesador para preprocesar observaciones del entorno Atari (e.g., SpaceInvaders-v0).\n",
        "\n",
        "    Hereda de rl.core.Processor y proporciona métodos para convertir observaciones RGB en\n",
        "    imágenes en escala de grises, redimensionarlas y normalizarlas, así como para limitar\n",
        "    las recompensas.\n",
        "\n",
        "    MÉTODOS:\n",
        "    --------\n",
        "        process_observation(observation): Convierte una observación RGB a escala de grises\n",
        "                                         y la redimensiona.\n",
        "        process_state_batch(batch): Normaliza un lote de estados dividiendo por 255.\n",
        "        process_reward(reward): Limita las recompensas a un rango [-1, 1].\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape=(INPUT_SHAPE)):\n",
        "        self.input_shape = input_shape\n",
        "        # Precargar una imagen negra para inicialización\n",
        "        self.black_frame = np.zeros(input_shape, dtype=np.uint8)\n",
        "\n",
        "    def process_observation(self, observation):\n",
        "        \"\"\"\n",
        "        Preprocesa una observación convirtiéndola a escala de grises y redimensionándola.\n",
        "\n",
        "        Parámetros:\n",
        "        -----------\n",
        "            observation (np.ndarray): Observación cruda del entorno con forma (height, width, channels).\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "            np.ndarray: Imagen en escala de grises redimensionada a INPUT_SHAPE (84, 84) en formato uint8.\n",
        "\n",
        "        Raises:\n",
        "            AssertionError: Si la observación no tiene 3 dimensiones o la forma procesada no coincide con INPUT_SHAPE.\n",
        "        \"\"\"\n",
        "        # Si la observación es None, devolver un marco negro\n",
        "        if observation is None:\n",
        "            return self.black_frame\n",
        "\n",
        "        assert observation.ndim == 3  # (height, width, channel)\n",
        "        # Crop the screen (remove the part below the player)\n",
        "        # [Up: Down, Left: right]\n",
        "        cropped_img = observation[18:-12, 4:-12]\n",
        "        # Optimización: usar cv2 para redimensionar y convertir a escala de grises (más rápido que PIL)\n",
        "        resized = cv2.resize(cropped_img, self.input_shape)\n",
        "        # Convertir a escala de grises si es necesario\n",
        "        if len(resized.shape) == 3:\n",
        "            gray = cv2.cvtColor(resized, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            gray = resized\n",
        "        assert gray.shape == self.input_shape\n",
        "        return gray.astype(np.uint8)\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        \"\"\"\n",
        "        Normaliza un lote de estados dividiendo los valores por 255.\n",
        "\n",
        "        Parámetros:\n",
        "        -----------\n",
        "            batch (np.ndarray): Lote de estados con valores en [0, 255].\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "            np.ndarray: Lote normalizado con valores en [0, 1] en formato float32.\n",
        "        \"\"\"\n",
        "        # Conversión directa a float32 y normalización\n",
        "        return batch.astype(np.float32) / 255.0\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        \"\"\"\n",
        "        Normaliza un lote de estados dividiendo los valores por 255.\n",
        "\n",
        "        Parámetros:\n",
        "        -----------\n",
        "            batch (np.ndarray): Lote de estados con valores en [0, 255].\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "            np.ndarray: Lote normalizado con valores en [0, 1] en formato float32.\n",
        "        \"\"\"\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "    def process_step(self, observation, reward, done, info):\n",
        "        \"\"\"\n",
        "        Procesa un paso completo del entorno.\n",
        "        \"\"\"\n",
        "        processed_observation = self.process_observation(observation)\n",
        "        processed_reward = self.process_reward(reward)\n",
        "        return processed_observation, processed_reward, done, info"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Revisar el entorno de juego"
      ],
      "metadata": {
        "id": "ptwluQRXedZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VwBXOBk43MP",
        "outputId": "1153a36e-53fe-4866-c851-020a848cffff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero de acciones disponibles: 6\n"
          ]
        }
      ],
      "source": [
        "print(\"Numero de acciones disponibles: \" + str(nb_actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT6osc3H43MP",
        "outputId": "709e1137-3e54-4102-9e32-074c581c9b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato de las observaciones:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(0, 255, (210, 160, 3), uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "print(\"Formato de las observaciones:\")\n",
        "env.observation_space"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observation = env.reset()\n",
        "for i in range(22):\n",
        "  if i > 20:\n",
        "    plt.imshow(observation)\n",
        "    plt.show()\n",
        "\n",
        "  observation, reward, done, info = env.step(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "7-BoOu_eeiAE",
        "outputId": "463c6d08-7327-4a16-9f29-880031328936"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las entradas preprocesadas en escala de grises y comparar originales y preprocesados.\n",
        "processor = AtariProcessor()\n",
        "obs_preprocessed = processor.process_observation(observation).reshape(INPUT_SHAPE)\n",
        "# Seleccionamos el primer frame y lo normalizamos\n",
        "frame = processor.process_state_batch(obs_preprocessed)\n",
        "# Visualizar en escala de grises\n",
        "plt.imshow(frame, cmap='gray')\n",
        "plt.show()\n",
        "print(observation.shape)\n",
        "print(obs_preprocessed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "vHJaGcAVelRY",
        "outputId": "3c0d6164-7f96-4636-9cf8-2c299854ce87"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(210, 160, 3)\n",
            "(84, 84)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clase FrameStack para apilar frames"
      ],
      "metadata": {
        "id": "xVe0dhbsfvc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FrameStack:\n",
        "    \"\"\"\n",
        "    Clase para gestionar una pila de fotogramas consecutivos del entorno, utilizada para capturar\n",
        "    el contexto temporal en juegos de Atari (e.g., SpaceInvaders-v0).\n",
        "\n",
        "    Mantiene una cola (deque) de fotogramas preprocesados con un tamaño máximo definido por\n",
        "    max_length, apilándolos para formar un estado con información de movimiento.\n",
        "\n",
        "    Atributos:\n",
        "    ----------\n",
        "        frames (deque): Cola de fotogramas preprocesados con longitud máxima max_length.\n",
        "        max_length (int): Número máximo de fotogramas a apilar (e.g., WINDOW_LENGTH).\n",
        "\n",
        "    MÉTODOS:\n",
        "    --------\n",
        "        append(frame): Añade un nuevo fotograma a la pila, eliminando el más antiguo si es necesario.\n",
        "        get_stacked_state(): Devuelve el estado apilado como un array NumPy.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_frames=4):\n",
        "        \"\"\"\n",
        "        Inicializa la pila de fotogramas.\n",
        "\n",
        "        Parámetros:\n",
        "        -----------\n",
        "            max_length (int): Número máximo de fotogramas a mantener en la pila.\n",
        "        \"\"\"\n",
        "        self.num_frames = num_frames\n",
        "        self.frames = deque([np.zeros((INPUT_SHAPE), dtype=np.int) for i in range(self.num_frames)], maxlen=self.num_frames)\n",
        "\n",
        "    def reset(self):\n",
        "        self.frames.clear()\n",
        "\n",
        "    def add_frame(self, frame, is_new_episode):\n",
        "        \"\"\"\n",
        "        Añade un fotograma preprocesado a la pila.\n",
        "\n",
        "        Parámetros:\n",
        "        -----------\n",
        "            frame (np.ndarray): Fotograma preprocesado (e.g., imagen en escala de grises de 84x84).\n",
        "        \"\"\"\n",
        "        # Si es el primer frame, llenamos el deque\n",
        "        if is_new_episode:\n",
        "            self.frames = deque([np.zeros((INPUT_SHAPE), dtype=np.int) for i in range(self.num_frames)], maxlen=self.num_frames)\n",
        "            for _ in range(self.num_frames):\n",
        "                self.frames.append(frame)\n",
        "        else:\n",
        "            self.frames.append(frame)\n",
        "\n",
        "    def get_state(self):\n",
        "        \"\"\"\n",
        "        Devuelve el estado apilado como un array NumPy con los fotogramas actuales.\n",
        "\n",
        "        Si la pila no está llena, repite el último fotograma hasta completar max_length.\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "            np.ndarray: Array de forma (84, 84, max_length) con los fotogramas apilados.\n",
        "        \"\"\"\n",
        "        # Convertir a array con shape (84, 84, 4)\n",
        "        return np.stack(self.frames, axis=-1)"
      ],
      "metadata": {
        "id": "gSJsJa41fzo7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clase ReplayMemory"
      ],
      "metadata": {
        "id": "j-yCJoGjf2Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayMemory:\n",
        "    \"\"\"ReplayMemory optimizada para evitar fugas de memoria\"\"\"\n",
        "\n",
        "    def __init__(self, capacity, state_shape):\n",
        "        self.capacity = capacity\n",
        "        self.position = 0\n",
        "        self.size = 0\n",
        "\n",
        "        # Pre-asignar arrays con el tamaño exacto\n",
        "        # Usar uint8 para estados (más eficiente que float32)\n",
        "        self.states = np.zeros((capacity, *state_shape), dtype=np.uint8)\n",
        "        self.actions = np.zeros(capacity, dtype=np.int32)\n",
        "        self.rewards = np.zeros(capacity, dtype=np.float32)\n",
        "        self.next_states = np.zeros((capacity, *state_shape), dtype=np.uint8)\n",
        "        self.dones = np.zeros(capacity, dtype=np.bool_)\n",
        "\n",
        "        print(f\"ReplayMemory creada: {capacity} samples, {state_shape} shape\")\n",
        "        memory_size = (\n",
        "            self.states.nbytes + self.next_states.nbytes +\n",
        "            self.actions.nbytes + self.rewards.nbytes + self.dones.nbytes\n",
        "        ) / (1024 * 1024)\n",
        "        print(f\"Memoria asignada: {memory_size:.2f} MB\")\n",
        "\n",
        "    def append(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Añade una experiencia al buffer de forma eficiente\"\"\"\n",
        "        # Convertir a uint8 para ahorrar memoria (estados son imágenes 0-255)\n",
        "        if state.dtype != np.uint8:\n",
        "            state = (state * 255).astype(np.uint8)\n",
        "        if next_state.dtype != np.uint8:\n",
        "            next_state = (next_state * 255).astype(np.uint8)\n",
        "\n",
        "        # Almacenar directamente en el array pre-asignado\n",
        "        self.states[self.position] = state\n",
        "        self.actions[self.position] = action\n",
        "        self.rewards[self.position] = reward\n",
        "        self.next_states[self.position] = next_state\n",
        "        self.dones[self.position] = done\n",
        "\n",
        "        # Actualizar posición circular\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "        self.size = min(self.size + 1, self.capacity)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Muestra un batch de experiencias de forma eficiente\"\"\"\n",
        "        if self.size < batch_size:\n",
        "            raise ValueError(f\"No hay suficientes samples ({self.size}) para batch_size ({batch_size})\")\n",
        "\n",
        "        # Generar índices aleatorios\n",
        "        indices = np.random.choice(self.size, batch_size, replace=False)\n",
        "\n",
        "        # Extraer batch y convertir de vuelta a float32 para el entrenamiento\n",
        "        batch_states = self.states[indices].astype(np.float32) / 255.0\n",
        "        batch_actions = self.actions[indices]\n",
        "        batch_rewards = self.rewards[indices]\n",
        "        batch_next_states = self.next_states[indices].astype(np.float32) / 255.0\n",
        "        batch_dones = self.dones[indices]\n",
        "\n",
        "        return batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"Limpia la memoria de forma segura\"\"\"\n",
        "        self.position = 0\n",
        "        self.size = 0\n",
        "        # No es necesario limpiar los arrays, se sobrescriben"
      ],
      "metadata": {
        "id": "ewKKozUaf-mG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clase PerformanceMonitor"
      ],
      "metadata": {
        "id": "No-SaTPRkQoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase para monitoreo de memoria y rendimiento\n",
        "class PerformanceMonitor(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, save_path='diagnosticos'):\n",
        "        self.save_path = save_path\n",
        "        self.episode_times = []\n",
        "        self.memory_usage = []\n",
        "        self.current_episode = 0\n",
        "        self.episode_start_time = None\n",
        "        self.episode_start_memory = None\n",
        "\n",
        "    def on_episode_begin(self, episode, logs={}):\n",
        "        self.episode_start_time = time.time()\n",
        "        self.episode_start_memory = psutil.Process().memory_info().rss / (1024 * 1024)\n",
        "        self.current_episode = episode\n",
        "        print(f\"Episodio {episode} comenzando. Memoria inicial: {self.episode_start_memory:.2f} MB\")\n",
        "\n",
        "    def on_episode_end(self, episode, logs={}):\n",
        "        end_time = time.time()\n",
        "        final_memory = psutil.Process().memory_info().rss / (1024 * 1024)\n",
        "        episode_duration = end_time - self.episode_start_time\n",
        "\n",
        "        self.episode_times.append(episode_duration)\n",
        "        self.memory_usage.append(final_memory)\n",
        "\n",
        "        print(f\"Episodio {episode} completado en {episode_duration:.2f} segundos\")\n",
        "        print(f\"Memoria final: {final_memory:.2f} MB (cambio: {final_memory - self.episode_start_memory:.2f} MB)\")\n",
        "\n",
        "        # Guardar diagnóstico cada 5 episodios\n",
        "        if (episode + 1) % 5 == 0:\n",
        "            self.save_diagnostics(episode)\n",
        "\n",
        "        # Forzar recolección de basura\n",
        "        gc.collect()\n",
        "\n",
        "    def save_diagnostics(self, episode):\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.episode_times)\n",
        "        plt.title('Tiempo por episodio')\n",
        "        plt.ylabel('Segundos')\n",
        "        plt.xlabel('Episodio')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.memory_usage)\n",
        "        plt.title('Uso de memoria')\n",
        "        plt.ylabel('MB')\n",
        "        plt.xlabel('Episodio')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.save_path}/rendimiento_episodio_{episode+1}.png\")\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "Wf2A5kDokNdS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Implementación de la red neuronal\n",
        "\n",
        "#### Definición de las redes neuronales"
      ],
      "metadata": {
        "id": "iTgDOJoCgISN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crearemos una clase para construir un red Q-profunda, con tres capas convolucionales, seguidas de una capa de aplanamiento y una capa completamente conectada."
      ],
      "metadata": {
        "id": "SFAzP0UigPVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CQ0dGSAUgP0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase base DQNetworkBase para evitar duplicación\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class DQNetworkBase(tf.keras.Model):\n",
        "    \"\"\"Base común para redes DQN y DDQN\n",
        "    Red neuronal Deep Q-Network (DQN) para aproximar la función Q en aprendizaje por refuerzo.\n",
        "\n",
        "    Esta clase implementa una red convolucional que recibe un estado (conjunto de frames)\n",
        "    y produce los valores Q para cada acción posible. Usa capas convolucionales seguidas\n",
        "    de capas totalmente conectadas, con activación ELU.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    state_size : tupla/lista - Dimensiones del estado de entrada (por ejemplo, [84, 84, 4]).\n",
        "    action_size : int        - Número de acciones posibles en el entorno.\n",
        "    learning_rate : float    - Tasa de aprendizaje para el optimizador Adam.\n",
        "    name : str, opcional     - Nombre del scope de TensorFlow para distinguir múltiples redes.\n",
        "    \"\"\"\n",
        "    def __init__(self, state_size, action_size, learning_rate, name='DQNetworkBase'):\n",
        "        super(DQNetworkBase, self).__init__(name=name)\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Configuración de capas\n",
        "        if K.image_data_format() == 'channels_last':\n",
        "            self.permute = Permute((2, 3, 1))\n",
        "        elif K.image_data_format() == 'channels_first':\n",
        "            self.permute = Permute((1, 2, 3))\n",
        "        else:\n",
        "            raise RuntimeError('Unknown image_dim_ordering.')\n",
        "\n",
        "        self.conv1 = Conv2D(32, (8, 8), strides=(4, 4), activation='relu')\n",
        "        self.conv2 = Conv2D(64, (4, 4), strides=(2, 2), activation='relu')\n",
        "        self.conv3 = Conv2D(64, (3, 3), strides=(1, 1), activation='relu')\n",
        "        self.flatten = Flatten()\n",
        "        self.fc = Dense(512, activation='relu')\n",
        "        self.output_layer = Dense(action_size, activation='linear')\n",
        "\n",
        "        # Optimizador\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    def _forward_pass(self, inputs):\n",
        "        \"\"\"\n",
        "        Ejecuta la red neuronal para un batch de estados y define la lógica para hacer la propagación hacia adelante\n",
        "        (forward pass).  Se llama automáticamente en una clase que hereda de tf.keras.Model o tf.keras.layers.Layer.\n",
        "\n",
        "        Parámetros:\n",
        "        -----------\n",
        "        inputs : tf.Tensor  - Tensor con los estados de entrada, shape = (batch_size, *state_size)\n",
        "        \"\"\"\n",
        "        # Hay un detalle importante a tener en cuenta: K.image_data_format() indica el formato que Keras está configurado\n",
        "        #   para usar por defecto, pero no necesariamente indica el formato de los datos que estás recibiendo en ese\n",
        "        #   momento específico. Para el problema específico con keras-rl, puede ser que la biblioteca esté proporcionando\n",
        "        # datos en un formato diferente al configurado en Keras. Por eso, una combinación de ambos enfoques podría ser lo\n",
        "        # mejor:\n",
        "        # Verificar la forma real de los datos de entrada\n",
        "        \"\"\"Forward pass con manejo inteligente del formato de canales\"\"\"\n",
        "        # Verificar la forma real de los datos de entrada\n",
        "        if len(inputs.shape) == 4 and inputs.shape[1] in [3, 4] and inputs.shape[2] in [84, 110]:\n",
        "            # Los datos tienen formato channels_first (batch, channels, height, width)\n",
        "            x = self.permute(inputs)\n",
        "            print(f\"Detectado formato channels_first en datos: {inputs.shape} -> {x.shape}\")\n",
        "        elif K.image_data_format() == 'channels_first' and len(inputs.shape) == 4:\n",
        "            # Keras está configurado para channels_first pero el modelo espera channels_last\n",
        "            x = self.permute(inputs)\n",
        "            print(f\"Permutando debido a configuración channels_first: {inputs.shape} -> {x.shape}\")\n",
        "        else:\n",
        "            # Formato ya compatible o caso especial\n",
        "            x = inputs\n",
        "\n",
        "        # CORREGIDO: Usar x en lugar de inputs\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        \"\"\"\n",
        "        Ejecuta la red neuronal para un batch de estados y define la lógica para hacer la propagación hacia adelante\n",
        "        (forward pass).  Se llama automáticamente en una clase que hereda de tf.keras.Model o tf.keras.layers.Layer.\n",
        "\n",
        "        Parámetros:\n",
        "        -----------\n",
        "        inputs : tf.Tensor  - Tensor con los estados de entrada, shape = (batch_size, *state_size)\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        tf.Tensor - Valores Q para cada acción, shape = (batch_size, action_size)\n",
        "        \"\"\"\n",
        "        return self._forward_pass(inputs)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'state_size': self.state_size,\n",
        "            'action_size': self.action_size,\n",
        "            'learning_rate': self.learning_rate,\n",
        "            'name': self.name,\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)"
      ],
      "metadata": {
        "id": "kP2vNpKnzkTl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DQNetwork simplificado\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class DQNetwork(DQNetworkBase):\n",
        "    \"\"\"Red DQN estándar\"\"\"\n",
        "    def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\n",
        "        super(DQNetwork, self).__init__(state_size, action_size, learning_rate, name=name)"
      ],
      "metadata": {
        "id": "lSrKAOx8Ok6Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de DDQNetwork independiente\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class DDQNetwork(DQNetworkBase):\n",
        "    \"\"\"Red Double DQN con redes principal y objetivo\"\"\"\n",
        "    def __init__(self, state_size, action_size, learning_rate, name='DDQNetwork'):\n",
        "        super(DDQNetwork, self).__init__(state_size, action_size, learning_rate, name=name)\n",
        "\n",
        "        # Red objetivo separada\n",
        "        self.target_network = self._build_target_network()\n",
        "\n",
        "        # Inicializar con los mismos pesos\n",
        "        self.update_target(tau=1.0)\n",
        "\n",
        "    def _build_target_network(self):\n",
        "        \"\"\"Construye la red objetivo con la misma arquitectura\"\"\"\n",
        "        inputs = Input(shape=self.state_size)\n",
        "        x = Conv2D(32, (8, 8), strides=(4, 4), activation='relu', padding='valid')(inputs)\n",
        "        x = Conv2D(64, (4, 4), strides=(2, 2), activation='relu', padding='valid')(x)\n",
        "        x = Conv2D(64, (3, 3), strides=(1, 1), activation='relu', padding='valid')(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        outputs = Dense(self.action_size, activation='linear')(x)\n",
        "\n",
        "        return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    def update_target(self, tau=1.0):\n",
        "        \"\"\"Actualiza los pesos de la red objetivo\"\"\"\n",
        "        main_weights = self.get_weights()\n",
        "        target_weights = self.target_network.get_weights()\n",
        "\n",
        "        updated_weights = []\n",
        "        for i in range(len(target_weights)):\n",
        "            updated_weights.append((1 - tau) * target_weights[i] + tau * main_weights[i])\n",
        "\n",
        "        self.target_network.set_weights(updated_weights)"
      ],
      "metadata": {
        "id": "qm4vt4leyndU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Implementación de la solución DQN\n",
        "\n",
        "#### Funciones auxiliares"
      ],
      "metadata": {
        "id": "d0DHvKNshvQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapear clases a prefijos\n",
        "class_to_prefix = {\n",
        "        DQNetwork: \"DQN\",\n",
        "        DDQNetwork: \"DDQN\" #,\n",
        "    #    DDQNetworkWithReplay: \"DDQN_Replay\",\n",
        "    #    DuelingDQNetworkWithReplay: \"DuelingDQN_Replay\"\n",
        "}"
      ],
      "metadata": {
        "id": "3pyO_DovhzyW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create a fixed version of the compute_q_values function\n",
        "def fixed_compute_q_values(self, state):\n",
        "    \"\"\"Compute Q-values for a given state.\"\"\"\n",
        "    # Get batch Q-values\n",
        "    q_values = self.compute_batch_q_values([state])\n",
        "\n",
        "    # Convert TensorFlow tensor to NumPy if needed\n",
        "    if isinstance(q_values, tf.Tensor):\n",
        "        q_values = q_values.numpy()\n",
        "\n",
        "    # Debug output\n",
        "    print(f\"Q-values shape: {q_values.shape}, nb_actions: {self.nb_actions}\")\n",
        "\n",
        "    # Flatten the Q-values - handle different shapes\n",
        "    if len(q_values.shape) > 1:\n",
        "        if q_values.shape[1] == self.nb_actions:\n",
        "            q_values = tf.keras.backend.get_value( q_values[0])\n",
        "        else:\n",
        "            # If shape doesn't match expected, reshape to match nb_actions\n",
        "            q_values = q_values.reshape(-1)[:self.nb_actions]\n",
        "\n",
        "    # Make sure we have the right number of Q-values\n",
        "    if len(q_values) != self.nb_actions:\n",
        "        print(f\"WARNING: Q-values shape {q_values.shape} doesn't match nb_actions {self.nb_actions}\")\n",
        "        # Pad or truncate to match nb_actions\n",
        "        if len(q_values) < self.nb_actions:\n",
        "            # Pad with zeros\n",
        "            q_values = np.pad(q_values, (0, self.nb_actions - len(q_values)))\n",
        "        else:\n",
        "            # Truncate\n",
        "            q_values = q_values[:self.nb_actions]\n",
        "\n",
        "    return q_values\n",
        "\n",
        "# Step 3: Create a fixed version of compute_batch_q_values\n",
        "def fixed_compute_batch_q_values(self, state_batch):\n",
        "    \"\"\"Compute Q-values for a batch of states.\"\"\"\n",
        "    # Process state batch\n",
        "    batch = self.process_state_batch(state_batch)\n",
        "\n",
        "    # Print shape for debugging\n",
        "    print(f\"Processed batch shape: {batch.shape}\")\n",
        "\n",
        "    try:\n",
        "        # Convert to tensor with correct dtype\n",
        "        tensor_batch = tf.convert_to_tensor(batch, dtype=tf.float32)\n",
        "\n",
        "        # Get Q-values using the model's call method directly\n",
        "        q_values = self.model(tensor_batch, training=False)\n",
        "\n",
        "        # Convert to NumPy if it's a tensor\n",
        "        if isinstance(q_values, tf.Tensor):\n",
        "            q_values = tf.keras.backend.get_value( q_values)\n",
        "\n",
        "        return q_values\n",
        "    except Exception as e:\n",
        "        print(f\"Error computing batch Q-values: {e}\")\n",
        "        # Return default Q-values as fallback\n",
        "        return np.zeros((len(state_batch), self.nb_actions))\n"
      ],
      "metadata": {
        "id": "ocXuoi6rmQaQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Apply our fixes to the DQN agent\n",
        "DQNAgent.compute_q_values = fixed_compute_q_values\n",
        "DQNAgent.compute_batch_q_values = fixed_compute_batch_q_values"
      ],
      "metadata": {
        "id": "z2Afsxq6mfb8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ENTRENAMIENTO** ***********"
      ],
      "metadata": {
        "id": "zgbzJyUjmTzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciar tracemalloc\n",
        "tracemalloc.start()\n",
        "# Suprimir advertencias\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "# Configurar TensorFlow\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "#state_size = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE  # e.g. (4, 84, 84)\n",
        "\n",
        "def crear_agente(env, dqnet_class, processor, state_size, action_size, window_length, gamma, prefijo,batch_size=32,\n",
        "                     learning_rate=0.00025, checkpoint_path='checkpoints',\n",
        "                     input_shape=(84, 84, 4), memoria_tamano=1000000,\n",
        "                     warmup_steps=50000, target_update_interval=10000, target_update_tau=0.001,\n",
        "                     epsilon_start=1.0, epsilon_min=0.1, epsilon_steps=1000000):\n",
        "    \"\"\"\n",
        "    Configura un agente DQN o DDQN con parámetros comunes.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    dqnet_class: Clase del modelo (e.g., DQNetwork, DDQNetwork, DDQNetworkWithReplay, DuelingDQNetworkWithReplay).\n",
        "            Se usa para verificar si el modelo soporta memoria de repetición y para determinar el prefijo de los\n",
        "            nombres de archivo de checkpoint.\n",
        "    env : gym.Env -        Entorno de OpenAI Gym\n",
        "    input_shape : tuple -  Forma del estado de entrada (altura, ancho, canales)\n",
        "    memoria_tamano : int - Tamaño de la memoria de experiencia\n",
        "    warmup_steps : int -   Pasos antes de empezar a aprender\n",
        "    target_update_interval : int - Frecuencia de actualización de la red objetivo\n",
        "    target_update_tau : float - Factor de actualización suave para la red objetivo\n",
        "    learning_rate : float -     Tasa de aprendizaje para el optimizador\n",
        "    epsilon_start, epsilon_min, epsilon_steps : float, float, int - Parámetros para la política epsilon-greedy con decaimiento lineal\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    agent : DQNAgent -       Agente configurado según los parámetros\n",
        "    model : tf.keras.Model o DDQNetwork - Modelo usado por el agente\n",
        "    processor : AtariProcessor -          Procesador de observaciones\n",
        "    callbacks : list -                    Lista de callbacks configurados\n",
        "    \"\"\"\n",
        "    # Optimización: limpiar memoria antes de crear modelo\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    # Verificar que el entorno esté disponible\n",
        "    if env is None:\n",
        "        raise ValueError(\"Debe proporcionar un entorno válido\")\n",
        "\n",
        "    # Verificar que las dimensiones de entrada sean correctas\n",
        "    # En TensorFlow con formato 'channels_last', necesitamos (height, width, channels)\n",
        "    if len(input_shape) != 3:\n",
        "        raise ValueError(f\"input_shape debe tener 3 dimensiones (height, width, channels), pero tiene {len(input_shape)}\")\n",
        "\n",
        "    # IMPORTANTE: Asegurarse de que state_size y input_shape sean consistentes\n",
        "    print(f\"Creando modelo con input_shape={input_shape} y state_size={state_size}\")\n",
        "\n",
        "    # IMPORTANTE: Asegurarse de que state_size y input_shape sean consistentes\n",
        "    print(f\"Creando modelo con input_shape={input_shape} y state_size={state_size}\")\n",
        "    # Crear modelo base\n",
        "    channels_last_shape = (*input_shape, window_length)\n",
        "    action_size = env.action_space.n\n",
        "\n",
        "    # Paso condicional de memory_size solo para DDQNetworkWithReplay\n",
        "    # if dqnet_class in [DDQNetworkWithReplay, DuelingDQNetworkWithReplay]:\n",
        "    #     model_base = dqnet_class(state_size, action_size, learning_rate, memory_size=memory_size, tau=tau)\n",
        "    # elif dqnet_class in [DDQNetwork]:  # si esta clase sí necesita tau\n",
        "    #     model_base = dqnet_class(state_size, action_size, learning_rate, tau=tau, gamma=gamma)\n",
        "    # else:\n",
        "    model_base = dqnet_class(channels_last_shape , action_size, learning_rate)\n",
        "    # Verificar el tipo de modelo y establecer enable_double_dqn correctamente\n",
        "    enable_double_dqn = (dqnet_class == DDQNetwork)\n",
        "\n",
        "    # Wrap funcional para Keras-RL\n",
        "    input_tensor  = tf.keras.Input(shape=channels_last_shape)\n",
        "    output = model_base(input_tensor )\n",
        "    model = tf.keras.Model(inputs=input_tensor , outputs=output)\n",
        "    model.summary()\n",
        "\n",
        "    memory = SequentialMemory(limit=memoria_tamano, window_length=input_shape[2])\n",
        "\n",
        "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "                              value_max=epsilon_start, value_min=epsilon_min, value_test=.05,\n",
        "                              nb_steps=epsilon_steps)\n",
        "    # Crear agente\n",
        "    dqn = DQNAgent(\n",
        "        model=model,\n",
        "        nb_actions=env.action_space.n,\n",
        "        memory=memory,\n",
        "        processor=processor,\n",
        "        nb_steps_warmup=warmup_steps,\n",
        "        target_model_update=target_update_interval if not enable_double_dqn else 1,\n",
        "        enable_double_dqn=enable_double_dqn,\n",
        "        gamma=gamma,       # Valor estándar óptimo\n",
        "        train_interval=4,  # Actualizar cada 4 pasos (óptimo)\n",
        "        delta_clip=1.0,    # Limitar los errores para estabilidad\n",
        "        batch_size=batch_size      # Tamaño de batch óptimo\n",
        "    )\n",
        "\n",
        "    # Compilar el agente\n",
        "    dqn.compile(Adam(learning_rate=learning_rate), metrics=['mae'])\n",
        "\n",
        "    # Configurar callbacks\n",
        "    tipo_str = prefijo\n",
        "    weights_filename = f'{tipo_str}_weights.h5f'\n",
        "    checkpoint_weights_filename = f'{tipo_str}_weights_{{step}}.h5f'\n",
        "    log_filename = f'{tipo_str}_log.json'\n",
        "    callbacks = [\n",
        "        ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000),\n",
        "        FileLogger(log_filename, interval=100),\n",
        "        PerformanceMonitor(save_path='diagnosticos')\n",
        "    ]\n",
        "\n",
        "    # Para DDQN, añadimos un callback simple para actualizar la red target\n",
        "    if dqnet_class  in [DDQNetwork]:\n",
        "        class SimpleTargetUpdate(tf.keras.callbacks.Callback):\n",
        "            def __init__(self, ddqn_model, update_interval, tau):\n",
        "                self.ddqn_model = ddqn_model\n",
        "                self.update_interval = update_interval\n",
        "                self.tau = tau\n",
        "                self.step_counter = 0\n",
        "\n",
        "            def on_step_end(self, step, logs={}):\n",
        "                self.step_counter += 1\n",
        "                if self.step_counter % self.update_interval == 0:\n",
        "                    self.ddqn_model.update_target(tau=self.tau)\n",
        "                    print(f\"Paso {self.step_counter}: Actualizada red objetivo con tau={self.tau}\")\n",
        "\n",
        "        callbacks.append(SimpleTargetUpdate(model, target_update_interval, target_update_tau))\n",
        "\n",
        "    return dqn, model, callbacks"
      ],
      "metadata": {
        "id": "6Lopk_9tiB0I"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kM65PKIxQic2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de utilidad para crear y comparar los modelos que se vayan creando\n",
        "def entrenar_modelo(model_type,\n",
        "                 state_size,\n",
        "                 action_size,\n",
        "                 total_episodios,\n",
        "                 max_steps,\n",
        "                 batch_size,\n",
        "                 gamma,\n",
        "                 epsilon_start,\n",
        "                 memory_size,\n",
        "                 tau,\n",
        "                 learning_rate=0.001,\n",
        "                 start_episode=0,\n",
        "                 checkpoints_dir=checkpoint_path,\n",
        "                 memory_path=None,\n",
        "                 num_steps=1000000  # Añadir este parámetro\n",
        "):\n",
        "    \"\"\"\n",
        "    Factory function para crear modelos DQN o DDQN.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "        model_type : str -       Tipo de modelo a entrenar. Puede ser 'DQN' o 'DDQN'.\n",
        "        state_size : tuple -     Dimensiones del estado de entrada (por ejemplo, (84, 84, 4)).\n",
        "        action_size : int-       Número de acciones posibles en el entorno.\n",
        "        total_episodios : int-   Número total de episodios de entrenamiento.\n",
        "        max_steps : int -        Número máximo de pasos por episodio.\n",
        "        batch_size : int -       Tamaño de los lotes para el entrenamiento.\n",
        "        gamma : float -          Factor de descuento para los futuros Q-valores.\n",
        "        epsilon_start : float -  Valor inicial de epsilon (probabilidad de exploración).\n",
        "        memory_size : int -      Tamaño máximo de la memoria de repetición (replay buffer).\n",
        "        tau : float -            Tasa de actualización suave para redes objetivo (target network).\n",
        "        learning_rate : float -  Tasa de aprendizaje para el optimizador (default: 0.001).\n",
        "        start_episode : int   -  Episodio desde el cual comenzar (por ejemplo, al reanudar desde un checkpoint) (default: 0).\n",
        "        checkpoints_dir : str -  Ruta al archivo de checkpoint (pesos del modelo guardados en formato `.h5`) para continuar entrenamiento (default: None).\n",
        "        memory_path : str -      Ruta al archivo de memoria de repetición guardada (`.pkl`) para restaurar la experiencia pasada (default: None).\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "        trained_dqn - El agente entrenado\n",
        "    \"\"\"\n",
        "    # Crear el procesador Atari\n",
        "    processor = AtariProcessor()\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "    if model_type.upper() == 'DQN':\n",
        "        print(\"Entrenando DQN simple para Space Invaders...\")\n",
        "        trained_dqn, dqn_model, dqn_callbacks = crear_agente(env, DQNetwork, processor, MODEL_INPUT_SHAPE ,\n",
        "                     action_size, WINDOW_LENGTH, gamma, prefijo=model_type.upper(), batch_size=batch_size,\n",
        "                     learning_rate=0.00025, checkpoint_path='checkpoints',\n",
        "                     input_shape=INPUT_SHAPE, memoria_tamano=1000000,\n",
        "                     warmup_steps=50000, target_update_interval=10000, target_update_tau=0.001,\n",
        "                     epsilon_start=1.0, epsilon_min=0.1, epsilon_steps=1000000)\n",
        "    elif model_type.upper() == 'DDQN':\n",
        "        print(\"Entrenando DDQN simple para Space Invaders...\")\n",
        "        trained_dqn, dqn_model, dqn_callbacks = crear_agente(env, DDQNetwork, processor, MODEL_INPUT_SHAPE ,\n",
        "                     action_size, WINDOW_LENGTH, gamma, prefijo=model_type.upper(), batch_size=batch_size,\n",
        "                     learning_rate=0.00025, checkpoint_path='checkpoints',\n",
        "                     input_shape=INPUT_SHAPE, memoria_tamano=1000000,\n",
        "                     warmup_steps=50000, target_update_interval=10000, target_update_tau=0.001,\n",
        "                     epsilon_start=1.0, epsilon_min=0.1, epsilon_steps=1000000)\n",
        "    elif model_type.upper() == 'DDQN_REPLAY':\n",
        "        print(\"Entrenando DDQN con Replay Memory para Space Invaders...\")\n",
        "        trained_dqn, dqn_model, dqn_callbacks = crear_agente(env, None, processor, MODEL_INPUT_SHAPE ,\n",
        "                     action_size, WINDOW_LENGTH, gamma, prefijo=model_type.upper(), batch_size=batch_size,\n",
        "                     learning_rate=0.00025, checkpoint_path='checkpoints',\n",
        "                     input_shape=INPUT_SHAPE, memoria_tamano=1000000,\n",
        "                     warmup_steps=50000, target_update_interval=10000, target_update_tau=0.001,\n",
        "                     epsilon_start=1.0, epsilon_min=0.1, epsilon_steps=1000000)\n",
        "    elif model_type.upper() == 'DUELING_DQN_REPLAY':\n",
        "        print(\"Entrenando Dueling DQN con Replay Memory para Space Invaders...\")\n",
        "        trained_dqn, dqn_model, dqn_callbacks = crear_agente(env, None, processor, MODEL_INPUT_SHAPE ,\n",
        "                     action_size, WINDOW_LENGTH, gamma, prefijo=model_type.upper(), batch_size=batch_size,\n",
        "                     learning_rate=0.00025, checkpoint_path='checkpoints',\n",
        "                     input_shape=INPUT_SHAPE, memoria_tamano=1000000,\n",
        "                     warmup_steps=50000, target_update_interval=10000, target_update_tau=0.001,\n",
        "                     epsilon_start=1.0, epsilon_min=0.1, epsilon_steps=1000000)\n",
        "    else:\n",
        "        raise ValueError(\"model_type debe ser 'DQN', 'DDQN', 'DDQN_REPLAY' o 'DUELING_DQN_REPLAY' \")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "\n",
        "    # Entrenar -------------------------------------\n",
        "    try:\n",
        "        print(f\"Iniciando entrenamiento de {model_type.upper()} por {num_steps} pasos...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Entrenar el agente DQN\n",
        "        trained_dqn.fit(env, nb_steps=num_steps, callbacks=dqn_callbacks, verbose=2)\n",
        "\n",
        "        training_time = (time.time() - start_time) / 60\n",
        "        print(f\"Entrenamiento completado en {training_time:.2f} minutos\")\n",
        "        # Guardar pesos finales\n",
        "        weights_filename = f\"{checkpoints_dir}/{model_type}_weights_final.h5f\"\n",
        "        trained_dqn.save_weights(weights_filename, overwrite=True)\n",
        "        print(f\"Modelo guardado en {weights_filename}\")\n",
        "        return trained_dqn\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nEntrenamiento interrumpido por el usuario\")\n",
        "        # Guardar pesos de emergencia\n",
        "        emergency_filename = f\"{checkpoints_dir}/{model_type}_weights_emergency.h5f\"\n",
        "        trained_dqn.save_weights(emergency_filename, overwrite=True)\n",
        "        print(f\"Modelo de emergencia guardado en {emergency_filename}\")\n",
        "        return trained_dqn\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError durante el entrenamiento: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "    return trained_dqn"
      ],
      "metadata": {
        "id": "MTCkURI3oARu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloque de Ejecución Principal ---\n",
        "if __name__ == \"__main__\":\n",
        "    tf.keras.backend.clear_session()\n",
        "    # Control global de si se entrena o solo se carga\n",
        "    training_global = True\n",
        "    # Control de renderizado durante el entrenamiento (no afecta la grabación de video final)\n",
        "    episode_render = False\n",
        "    # Asegurar que existe el directorio\n",
        "    os.makedirs(checkpoint_path, exist_ok=True)\n",
        "    # Optimizar configuración de TensorFlow\n",
        "    optimizar_tensorflow()\n",
        "\n",
        "    # ------------ ENTRENAMIENTO Y CARGA DE MEJORES MODELOS --------------------------------------\n",
        "\n",
        "    # Diccionario para guardar los *mejores modelos cargados/entrenados* de cada tipo\n",
        "    trained_models = {}\n",
        "    # Lista de tuplas (nombre_modelo, clase_modelo, flag_entrenamiento_especifico)\n",
        "    modelos_a_procesar = [\n",
        "        ('DQN', DQNetwork, True), # NO Entrenar DQN\n",
        "        ('DDQN', DDQNetwork, False), # No entrenar DDQN, solo cargar si existe\n",
        "        ('DDQN_REPLAY', DQNetwork, False), # No entrenar DDQN_REPLAY\n",
        "        ('DUELING_DQN_REPLAY', DQNetwork, False) # Entrenar DuelingDQN_REPLAY\n",
        "    ]\n",
        "\n",
        "    for model_name, model_class, training_specific_flag in modelos_a_procesar:\n",
        "        # La bandera de entrenamiento final es la global AND la específica del modelo\n",
        "        entrenarSN = training_global and training_specific_flag\n",
        "        model_instance = None\n",
        "        if entrenarSN:\n",
        "            # Llama a la función crear_modelo existente para el entrenamiento.\n",
        "            # crear_modelo ya maneja los parámetros específicos de cada tipo de red.\n",
        "            model_instance = entrenar_modelo(\n",
        "                model_name, MODEL_INPUT_SHAPE, action_size,\n",
        "                total_episodios, max_steps, batch_size, gamma, epsilon_start, # Pasando los nuevos parámetros\n",
        "                memory_size=memory_size, tau=tau, learning_rate=learning_rate,\n",
        "                start_episode=0, checkpoints_dir=checkpoint_path\n",
        "            )\n",
        "        else:\n",
        "            # Si no estamos entrenando, creamos una instancia vacía para cargar pesos.\n",
        "            # Necesitamos instanciar la clase de modelo directamente.\n",
        "            if model_name in ['DDQN_REPLAY', 'DUELING_DQN_REPLAY']:\n",
        "                model_instance = model_class(state_size, action_size, learning_rate, memory_size=memory_size, tau=tau)\n",
        "            elif model_name == 'DDQN':\n",
        "                model_instance = model_class(state_size, action_size, learning_rate, tau=tau)\n",
        "            else: # 'DQN'\n",
        "                model_instance = model_class(state_size, action_size, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "CAsEf6rOl0GF",
        "outputId": "5c47e323-6f4f-468a-9399-f8ea5e5e1b4c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow optimizado para 2 cores CPU\n",
            "------------------------------------------------------------\n",
            "Entrenando DQN simple para Space Invaders...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "input_shape debe tener 3 dimensiones (height, width, channels), pero tiene 2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-214820624.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Llama a la función crear_modelo existente para el entrenamiento.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# crear_modelo ya maneja los parámetros específicos de cada tipo de red.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             model_instance = entrenar_modelo(\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_INPUT_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mtotal_episodios\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Pasando los nuevos parámetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-25-1419422343.py\u001b[0m in \u001b[0;36mentrenar_modelo\u001b[0;34m(model_type, state_size, action_size, total_episodios, max_steps, batch_size, gamma, epsilon_start, memory_size, tau, learning_rate, start_episode, checkpoints_dir, memory_path, num_steps)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DQN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Entrenando DQN simple para Space Invaders...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         trained_dqn, dqn_model, dqn_callbacks = crear_agente(env, DQNetwork, processor, MODEL_INPUT_SHAPE ,\n\u001b[0m\u001b[1;32m     49\u001b[0m                      \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWINDOW_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefijo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                      \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-24-1598714889.py\u001b[0m in \u001b[0;36mcrear_agente\u001b[0;34m(env, dqnet_class, processor, state_size, action_size, window_length, gamma, prefijo, batch_size, learning_rate, checkpoint_path, input_shape, memoria_tamano, warmup_steps, target_update_interval, target_update_tau, epsilon_start, epsilon_min, epsilon_steps)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# En TensorFlow con formato 'channels_last', necesitamos (height, width, channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"input_shape debe tener 3 dimensiones (height, width, channels), pero tiene {len(input_shape)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# IMPORTANTE: Asegurarse de que state_size y input_shape sean consistentes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: input_shape debe tener 3 dimensiones (height, width, channels), pero tiene 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1NPL3jnj9bqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY4KZPwP43MQ"
      },
      "outputs": [],
      "source": [
        "# Testing part\n",
        "#weights_filename = 'dqn_{}_weights.h5f'.format(env_name)\n",
        "weights_filename = \"dqn_BreakoutDeterministic-v4_weights_1750000.h5f\"\n",
        "dqn.load_weights(weights_filename)\n",
        "dqn.test(env, nb_episodes=10, visualize=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para evaluar el modelo\n",
        "def evaluar_modelo(dqn, env, num_episodes=10, render=True, record_video=False):\n",
        "    \"\"\"\n",
        "    Evalúa un modelo DQN o DDQN.\n",
        "\n",
        "    Args:\n",
        "        dqn: Agente DQN entrenado\n",
        "        env: Entorno de gym\n",
        "        num_episodes: Número de episodios para evaluar\n",
        "        render: Si se debe mostrar la visualización\n",
        "        record_video: Si se debe grabar video\n",
        "\n",
        "    Returns:\n",
        "        Lista de recompensas por episodio\n",
        "    \"\"\"\n",
        "    rewards = []\n",
        "\n",
        "    # Configurar grabación de video si es necesario\n",
        "    if record_video and gym.wrappers:\n",
        "        env = gym.wrappers.RecordVideo(\n",
        "            env,\n",
        "            f\"videos/{dqn.__class__.__name__}\",\n",
        "            episode_trigger=lambda x: True\n",
        "        )\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        state = dqn.processor.process_observation(state)\n",
        "\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        steps = 0\n",
        "\n",
        "        while not done:\n",
        "            if render:\n",
        "                env.render()\n",
        "\n",
        "            # Seleccionar acción\n",
        "            action = dqn.forward(state)\n",
        "\n",
        "            # Ejecutar acción\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            next_state = dqn.processor.process_observation(next_state)\n",
        "\n",
        "            # Actualizar estado y recompensa\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            steps += 1\n",
        "\n",
        "        print(f\"Episodio {episode+1}/{num_episodes}: Recompensa = {total_reward}, Pasos = {steps}\")\n",
        "        rewards.append(total_reward)\n",
        "\n",
        "    avg_reward = np.mean(rewards)\n",
        "    print(f\"\\nRecompensa media: {avg_reward:.2f} ± {np.std(rewards):.2f}\")\n",
        "    print(f\"Mejor episodio: {max(rewards):.2f}, Peor episodio: {min(rewards):.2f}\")\n",
        "\n",
        "    return rewards"
      ],
      "metadata": {
        "id": "6GZzkrK72yj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68dzFiUS2U6L"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}